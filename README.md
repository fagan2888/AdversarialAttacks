# AdversarialAttacks


The aim of this study is to understand some classical problems related to adversarial at- tacks that are presented by Goodfellow et al. in [1]. Multiple approaches are proposed to underline the properties of the adversarial attacks. In particular, we try to reproduce and observe some attacks properties exposed in Towards Deep Learning Models Resistant to Adversarial Attacks, Madry et al. [2].


## The results

You can find all our results in the submission report ```adversarial_attacks_report.pdf```. 



*Adversarial attacks grid-search 

*Black box attacks: analysis of convolution neural networks dimensions

*Bias/Variance trade-off: Impact on classifier robustness 

*Defending against adversarial attacks 


## References 


[1] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and Harness- ing Adversarial Examples. 2014. arXiv:   1412.6572 [stat.ML]. <br/>
[2] Aleksander Madry et al. Towards Deep Learning Models Resistant to Adversarial At- tacks. 2017. arXiv: 1706.06083  [stat.ML]. <br/>
[3] Alexandre Araujo et al. Robust Neural Networks using Randomized Adversarial Train- ing. 2019. arXiv: 1903.10219 [cs.LG]. <br/>
[4] Ramprasaath R. et al. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization. 2019. url: https://arxiv.org/pdf/1610.02391.pdf. <br/>
