# AdversarialAttacks


The aim of this study is to understand some classical problems related to adversarial at- tacks that are presented by Goodfellow et al. in [1]. Multiple approaches are proposed to underline the properties of the adversarial attacks. In particular, we try to reproduce and observe some attacks properties exposed in Towards Deep Learning Models Resistant to Adversarial Attacks, Madry et al. [2].


## The results

You can find all our results in the submission report ```adversarial_attacks_report.pdf```. 

Also, for the following topics, the codes are in the folders bellow: 

* **Adversarial attacks grid-search:** check the code in ```remy```

* **Black box attacks: analysis of convolution neural networks dimensions:** check the code in ```hippolyte```

* **Bias/Variance trade-off: Impact on classifier robustness:** check the code in ```theo```

* **Defending against adversarial attacks:** check the code in ```eymeric``` 


## References 


[1] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and Harness- ing Adversarial Examples. 2014. arXiv:   1412.6572 [stat.ML]. <br/>
[2] Aleksander Madry et al. Towards Deep Learning Models Resistant to Adversarial At- tacks. 2017. arXiv: 1706.06083  [stat.ML]. <br/>
[3] Alexandre Araujo et al. Robust Neural Networks using Randomized Adversarial Train- ing. 2019. arXiv: 1903.10219 [cs.LG]. <br/>
[4] Ramprasaath R. et al. Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization. 2019. url: arXiv : 1610.02391. <br/>
